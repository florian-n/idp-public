{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\")))\n",
    "\n",
    "# os.environ['JAX_PLATFORM_NAME'] = \"cpu\"\n",
    "# os.environ['JAX_PLATFORMS'] = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-11 20:27:59.852341: W external/xla/xla/service/gpu/nvptx_compiler.cc:765] The NVIDIA driver's CUDA version is 12.2 which is older than the ptxas CUDA version (12.5.82). Because the driver is older than the ptxas version, XLA is disabling parallel compilation, which may slow down compilation. You should update your NVIDIA driver or use the NVIDIA-provided CUDA forward compatibility packages.\n",
      "/home/florian/anaconda3/envs/jaxidp/lib/python3.11/site-packages/google/colab/data_table.py:30: UserWarning: IPython.utils.traitlets has moved to a top-level traitlets package.\n",
      "  from IPython.utils import traitlets as _traitlets\n"
     ]
    }
   ],
   "source": [
    "import jax.numpy as jnp\n",
    "import jax\n",
    "\n",
    "import numpy as onp\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "from simulation.simulate_full import run_entire_simulation\n",
    "\n",
    "from analyzers import defaultvalues as dv, database, loss as loss_anaylzer, gradients as grad_analyzer\n",
    "\n",
    "database.set_filename(\"../data/grad_analyzer/nsnaps_scan.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 50 100 150 200 250]\n"
     ]
    }
   ],
   "source": [
    "N_GRADIENTS = 4\n",
    "nsnaps_values = onp.array([50, 100, 150, 200, 250])\n",
    "print(nsnaps_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_info(grads):\n",
    "    amean, astd = grad_analyzer.analyze_gradients_absolute(grads)\n",
    "    mmean, mstd = grad_analyzer.analyze_gradients_magnitudal(grads)\n",
    "\n",
    "    print(f\"Absolute mean: {amean}, Absolute std: {astd}\")\n",
    "    print(f\"Magnitudal mean: {mmean}, Magnitudal std: {mstd}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== for 50 snapshots ====\n",
      "1.0682571381189187e+51\n",
      "3.6116808405700227e+49\n",
      "6.388790338950187e+49\n",
      "3.5521318653325285e+49\n",
      "Absolute mean: 3.009457921418615e+50, Absolute std: 4.431556402772743e+50\n",
      "Magnitudal mean: 49.985573221139035, Magnitudal std: 0.6109182353322882\n",
      "==== for 100 snapshots ====\n",
      "7.977811366993957e+48\n",
      "-1.568379530775108e+52\n",
      "-1.7122023968295645e+48\n",
      "3.4814759459220925e+49\n",
      "Absolute mean: 3.932075020243531e+51, Absolute std: 6.784870264801117e+51\n",
      "Magnitudal mean: 49.71816335712697, Magnitudal std: 1.5032004092682942\n",
      "==== for 150 snapshots ====\n",
      "1.9738864952038912e+46\n",
      "6.444583748853121e+47\n",
      "-7.272063785885953e+48\n",
      "-3.370201461158549e+45\n",
      "Absolute mean: 1.9849078067961156e+48, Absolute std: 3.0634622275327867e+48\n",
      "Magnitudal mean: 47.12345764741994, Magnitudal std: 1.2965306194621937\n",
      "==== for 200 snapshots ====\n",
      "3.2767264370563838e+47\n",
      "1.453417854244644e+50\n",
      "-4.872166936306448e+52\n",
      "-1.2232716412626552e+46\n",
      "Absolute mean: 1.2216837763462264e+52, Absolute std: 2.1076157679418553e+52\n",
      "Magnitudal mean: 49.11326893598928, Magnitudal std: 2.529108915897649\n",
      "==== for 250 snapshots ====\n",
      "3.153562010005637e+50\n",
      "1.4524549434600825e+50\n",
      "-5.751691223947205e+50\n",
      "1.0569105083280322e+52\n",
      "Absolute mean: 2.9012189752554035e+51, Absolute std: 4.429702625413683e+51\n",
      "Magnitudal mean: 50.86118445581357, Magnitudal std: 0.7040144559290721\n"
     ]
    }
   ],
   "source": [
    "for nsnaps in nsnaps_values:\n",
    "    existing_keys = database.get_existing_keys()\n",
    "    if nsnaps in existing_keys:\n",
    "        print(f\"Skipping {nsnaps}, was already computed\")\n",
    "        continue\n",
    "\n",
    "    grads = []\n",
    "    print(f\"==== for {nsnaps} snapshots ====\")\n",
    "    for i in range(1, N_GRADIENTS + 1):\n",
    "        key = random.randrange(0, 20000)\n",
    "        def simulation_wrapper(LJ_SIGMA_OO: float) -> float:\n",
    "            prediction = run_entire_simulation(\n",
    "                LJ_SIGMA_OO, \n",
    "                dv.N_STEPS, \n",
    "                dv.N_MOLECULES_PER_AXIS, \n",
    "                nsnaps, \n",
    "                dv.N_Q, \n",
    "                key)\n",
    "            reference = run_entire_simulation(\n",
    "                dv.LJ_SIGMA_OO, \n",
    "                dv.N_STEPS, \n",
    "                dv.N_MOLECULES_PER_AXIS, \n",
    "                nsnaps, \n",
    "                dv.N_Q, \n",
    "                key)\n",
    "            return loss_anaylzer.L1_loss(prediction, reference)\n",
    "        grad_fn = jax.grad(simulation_wrapper)\n",
    "        grad = grad_fn(3.1)\n",
    "        print(grad)\n",
    "        grads.append(grad)\n",
    "\n",
    "    grads = onp.array(grads)\n",
    "    print_info(grads)\n",
    "    database.save_intermediate_result(nsnaps, grads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== for 250 snapshots ====\n",
      "Absolute mean: 3.009457921418615e+50, Absolute std: 4.431556402772743e+50\n",
      "Magnitudal mean: 49.985573221139035, Magnitudal std: 0.6109182353322882\n",
      "==== for 250 snapshots ====\n",
      "Absolute mean: 3.932075020243531e+51, Absolute std: 6.784870264801117e+51\n",
      "Magnitudal mean: 49.71816335712697, Magnitudal std: 1.5032004092682942\n",
      "==== for 250 snapshots ====\n",
      "Absolute mean: 1.9849078067961156e+48, Absolute std: 3.0634622275327867e+48\n",
      "Magnitudal mean: 47.12345764741994, Magnitudal std: 1.2965306194621937\n",
      "==== for 250 snapshots ====\n",
      "Absolute mean: 1.2216837763462264e+52, Absolute std: 2.1076157679418553e+52\n",
      "Magnitudal mean: 49.11326893598928, Magnitudal std: 2.529108915897649\n",
      "==== for 250 snapshots ====\n",
      "Absolute mean: 2.9012189752554035e+51, Absolute std: 4.429702625413683e+51\n",
      "Magnitudal mean: 50.86118445581357, Magnitudal std: 0.7040144559290721\n"
     ]
    }
   ],
   "source": [
    "keys, values = database.load_result()\n",
    "for key, grads in zip(keys, values):\n",
    "    print(f\"==== for {nsnaps} snapshots ====\")\n",
    "    print_info(grads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (jaxidp)",
   "language": "python",
   "name": "jaxidp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
